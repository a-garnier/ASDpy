# -*- coding: utf-8 -*-
"""CNN_P2_valid.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-zHzxEvCgKh73M0ylfmXxbBCHN9iTro8
"""

# Strategy:
#
# STEP 2:
#  * do the same with validation data (normal and anomalous sounds)
# si les données correspondent à un défaut, prendre l'oppsé de la valeur
# calculer les proba d'appartenance de chaque son en faisant des batchs par spectrogramme
# spectrogrammes OK : quels résultats / proportion de bons classements
# spectrogrammes défaut : quel résultat / proportion de bons classements

# Author : Antoine
# First try of classification with KNN
# use only fan data, use normal and anomalous data for training
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt # Pour l'affichage d'images

from joblib import dump, load

from sklearn import neighbors
from sklearn.model_selection import train_test_split

#import numpy as np # Pour la manipulation de tableaux
#import pandas as pd # Pour manipuler des DataFrames pandas

from matplotlib import cm # Pour importer de nouvelles cartes de couleur
# %matplotlib inline

from keras.models import Sequential # Pour construire un réseau de neurones
from keras.layers import Dense # Pour instancier une couche dense
from keras.utils import np_utils

import itertools # Pour créer des iterateurs

from sklearn import metrics # Pour évaluer les modèles

#chargement du modèle
from keras.models import load_model

model_save_name = 'nn1.h5'
path = F"/drive/MyDrive/asdpy/models/{model_save_name}" 
model = load_model(path)

model.summary()

machines = [            # TEST DATA SIZE
    'fan',              # (1875, 40065)
    'pump',             # (856, 40065)
    'slider',           # (1290, 40065)
    'ToyCar',           # (2459, 44033)
    'ToyConveyor',      # (3509, 40065)
    'valve'             # (879, 40065)
]

# machines = ['verif_1', 'verif_2']

id_machine = 0
height = 128

# init array with expected width (equals image heigh + one for target)

set = 'test'

for machine in machines:

    # identifiant de la machine
    id_machine = id_machine + 1

    print(machine, '/', id_machine)

    # example : '../data/fan/train_png/'
    # working_directory = '../../data/'+machine+'/'
    working_directory = '/drive/MyDrive/asdpy/data/'

    # data file example: df_fan_train.joblib
    # numpy ndarray
    # dernière colonne = type de donnée, normal ou anomalie
    data_array = load(working_directory + 'df_'+machine+'_'+set+'.joblib')

    # limit data to spare RAM 
    if data_array.shape[0] > 2500:
      data_array = data_array[:2500,:]

    print(data_array.shape)

    nb_images = data_array.shape[0]
    pixels = data_array.shape[1] - 1
    width = int(pixels/height)

    #print("nb_images : ", nb_images)
    #print("width : ", width)

    for i in range(nb_images):
        img = data_array[i]
        type = img[-1]

        #print("img.shape :")
        #print(img.shape) # (40065,)
        #print(img)
        #print("type :")
        #print(type)

        lines = img[0:-1].reshape(height,width).T
        #print("lines :")
        #print(lines)

        id_machine_pred = predictImageType(model, lines)

        print("id_machine : ", id_machine, " / ", id_machine_pred, "(type ", type,")")
        # break


    # break



    # 14 minutes pour les 4 premieres machines...
    # 16 secondes pour 5 machines une fois optimisé
    # 45 secondes avec les 6 jeux de train et bridage à 2500 lignes par jeu

def predictImageType(model, lines):
  pred = model.predict(lines).mean(axis=0)
  #print("pred :")
  #print(np.round(pred,2))
  #print("pred.shape :")
  #print(pred.shape)

  idx_max = pred.argmax()
  #print("idx max :")
  #print(idx_max)
  return idx_max+1

predictImageType(model, lines)

predictImageType(model, lines)

id_machine = 0
height = 128

# init array with expected width (equals image heigh + one for target)
global_array = np.empty([0, height+1])

set = 'test'

for machine in machines:

    # identifiant de la machine
    id_machine = id_machine + 1

    print(machine, '/', id_machine)

    # example : '../data/fan/train_png/'
    # working_directory = '../../data/'+machine+'/'
    working_directory = '/drive/MyDrive/asdpy/data/'

    # data file example: df_fan_train.joblib
    # numpy ndarray
    # dernière colonne = type de donnée, normal ou anomalie
    data_array = load(working_directory + 'df_'+machine+'_'+set+'.joblib')

    # limit data to spare RAM 
    if data_array.shape[0] > 2500:
      data_array = data_array[:2500,:]

    print(data_array.shape)

    nb_images = data_array.shape[0]
    pixels = data_array.shape[1] - 1
    width = int(pixels/height)

    #print("nb_images : ", nb_images)
    #print("width : ", width)

    loop_array = data_array[:,0:-1].reshape(height,width*nb_images).T

    # vecteur aussi long que le nombre de lignes verticales
    id_machine_col = np.ones((width*nb_images,1), dtype=np.int16)*id_machine

    # colle le vecteur à droite de l'array
    loop_array = np.append(loop_array, id_machine_col, axis=1)
  
    # ajoute au tableau global
    global_array = np.append(global_array, loop_array, axis=0)

    # 14 minutes pour les 4 premieres machines...
    # 16 secondes pour 5 machines une fois optimisé
    # 45 secondes avec les 6 jeux de train et bridage à 2500 lignes par jeu

print("CREATE TRAINING DATAFRAME...")

# réduit la dimension de l'array pour les tests
np.random.shuffle(global_array)
data = global_array[0:1000*1000,:]

df = pd.DataFrame(data)

# séparation des données de la cible
data = df.iloc[:,0:-1]
target = df.iloc[:,-1:]

print("SPLIT DATA...")
# séparation des données d'entrainement (70%) et de test (30%)
X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.30, random_state=66)

y_train = np_utils.to_categorical(y_train, dtype = 'int')
y_test = np_utils.to_categorical(y_test, dtype = 'int')

print("y_test.shape")
print(y_test.shape)

num_pixels = X_train.shape[1]
num_classes = y_test.shape[1]

print("num_classes : ", num_classes)

# prédiction des données
# about 40 seconds
test_pred = model.predict(X_test)

# score du modèle
score = model.evaluate(X_test, y_test)
print(score)

# Prediction de l'échantillon de test
test_pred = model.predict(X_test)

test_pred_class = np.argmax(test_pred, axis=1)
y_test_class = np.argmax(y_test, axis=1)

print("Performances du modele :")
print(metrics.classification_report(y_test_class, test_pred_class))

# affiche la matrice de confusion sous forme de tableau coloré
classes = range(0,num_classes)

plt.figure()

# matrice de confusion
cnf_matrix = metrics.confusion_matrix(y_test_class, test_pred_class)

plt.imshow(cnf_matrix, interpolation='nearest',cmap='Blues')
plt.title("Matrice de confusion")
plt.colorbar()
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes)
plt.yticks(tick_marks, classes)

# texte et couleur
for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):
    plt.text(j, i, cnf_matrix[i, j],
             horizontalalignment = "center",
             color = "white" if cnf_matrix[i, j] > ( cnf_matrix.max() / 2) else "black")

plt.ylabel('Vrais labels')
plt.xlabel('Labels prédits')
plt.show()